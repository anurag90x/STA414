
> source("neuralnet.r")

> source("pca.r")

> # Fit neural network model to data, and plot squared error and sum of
> # absolute values of weights over training run.
> training_data <- function( .... [TRUNCATED] 

> find_pred_error <- function(class_pred,valy)
+ {
+   error <- 0
+   for( i in 1:length(valy))
+   {
+     if (class_pred[i]!=valy[i])
+     {
+      .... [TRUNCATED] 

> find_test_classes <- function(testx,weights,skel,lambda,testy)
+ {
+   wl <- relist(weights,skel)
+   lin_basis <- mlp_forward(testx,wl)
+  # print  .... [TRUNCATED] 

> try_different_components<- function()
+ {
+   
+   m <- 10   # number of hidden units
+   lambda <- 0
+   error <- c(0,0,0)
+   test_error <- c(0,0, .... [TRUNCATED] 

> trnx <- training_data("a3trnx.txt")

> trny <- training_data("a3trny.txt")

> tstx <- training_data("a3tstx.txt")

> tsty <- training_data("a3tsty.txt")

> trnx_est <- trnx[1:1000,]

> trnx_val <- trnx[1001:1300,]

> trny_est <- trny[1:1000]

> trny_val <- trny[1001:1300]

> m <- 10 #number of hidden units

> eta <- 0.001

> pca <- c(40)

> iters <- 1

> "
+ 
+ eigenvec_est <- pca.vectors(trnx_est,pca[i])
+ trnx_est_proj <- pca.proj(eigenvec_est,trnx_est)
+ 
+ eigenvec_val <- pca.vectors(trnx_val,pca ..." ... [TRUNCATED] 
[1] "\n\neigenvec_est <- pca.vectors(trnx_est,pca[i])\ntrnx_est_proj <- pca.proj(eigenvec_est,trnx_est)\n\neigenvec_val <- pca.vectors(trnx_val,pca[i])\ntrnx_val_proj <- pca.proj(eigenvec_est,trnx_val)\n"

> log_ll_mats <- try_different_components()
